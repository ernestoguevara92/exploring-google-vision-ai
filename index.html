<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google Vision AI</title>
    <style>
        #results {
        position: fixed;
        top: 50px;
        left: 10px;
        color: white;
        }
  
        #results span {
        margin: 5px 5px;
        }
        
        video {
        position: fixed;
        top: 0;
        left: 0;
        }
  
        h1 {
        position: fixed;
        bottom: 0;
        left: 0;
        }
  
        button {
        position: fixed;
        top: 0;
        left: 0;
        }
    </style>
</head>
<body>
    <h1>Google Vision AI</h1>

    <video autoplay="true" id="videoElement"></video>
    <button id="vision_button">Analyze</button>
    <div id="use-type">
        <input type="radio" id="label-detection" name="type" value="LABEL_DETECTION"> Label Detections
        <input type="radio" id="text-detection" name="type" value="TEXT_DETECTION"> Text Detection
    </div>

    <div id='results'></div>
    
    <script>

        var useType = document.querySelector('input[name="type"]:checked').value;

      // Access camera 
      var video = document.querySelector("#videoElement");      
      if (navigator.mediaDevices.getUserMedia) {       
	  navigator.mediaDevices.getUserMedia({video: true})
	      .then(function(stream) {
		  video.srcObject = stream;
	      })
	      .catch(function(err) {
		  console.log("Something went wrong!");
	      });
      }

      // We only get to work when the vision button is clicked
      document.querySelector("#vision_button").addEventListener('click', evt => {
	  // extract image as base64, scale it down to reduce data transfer speed	  
	  var scale = 0.25;
	  var canvas = document.createElement("canvas");
          canvas.width = video.videoWidth * scale;
          canvas.height = video.videoHeight * scale;
          canvas.getContext('2d')
              .drawImage(video, 0, 0, canvas.width, canvas.height);

	  // dataUrl contains base64 version of image
          var dataUrl = canvas.toDataURL();

	  // Send image to google to analyze
	  // Documentation of the annotate feature: https://cloud.google.com/vision/docs/reference/rest/v1/images/annotate 
	  fetch('https://vision.googleapis.com/v1/images:annotate?key=API-KEY', {
	      method: 'POST',
	      headers: {
		  'Content-Type': 'application/json'
	      },
	      body: JSON.stringify({
		  requests: [
		      {
			  features: {
			      type: useType
			  },
			  image: {
			      // have to extract only the image data from dataURL
			      content: dataUrl.substring('data:image/png;base64,'.length)
			  }
		      }
		  ]
	      })
	  }).then( resp => {
	      return resp.json();
	  }).then( json => {
	      // Simply output the response
	      console.log(json);
	      results.innerHTML = '';
	      json.responses[0].labelAnnotations.forEach( annotation => {
		  let description = document.createElement('span');
		  let score = document.createElement('span');

		  let div = document.createElement('div');
		  description.innerText = annotation.description;
		  score.innerText = annotation.score;

		  div.append(description,score);

		  results.append(div);
	      });
	  });
      });
      
    </script>
</body>
</html>